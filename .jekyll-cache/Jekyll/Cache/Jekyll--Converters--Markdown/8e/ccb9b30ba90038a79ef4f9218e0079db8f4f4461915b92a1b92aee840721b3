I"v<!-- https://github.com/allrobot/Study-Blog/raw/main/assets/images/ -->

<h2 id="矩阵和向量">矩阵和向量</h2>

<p>矩阵是矩形数组的，由行数i和列数j构成</p>

<p>4*2矩阵，用数学符号表现为$R^{4*2}$</p>

\[A=
\begin{equation*}\begin{bmatrix}
1402&amp;191  \\
1372&amp;821  \\
949&amp;1437  \\
147&amp;1448
\end{bmatrix}\end{equation*}\]

<p>$A_{ij}$，那么$A_{11}=1402,A_{22}=821,A_{32}=1437$</p>

<p>2*3矩阵，用数学符号表现为$R^{2*3}$</p>

\[\\
\begin{equation*}\begin{bmatrix}
1&amp;2&amp;3  \\
4&amp;5&amp;6
\end{bmatrix}\end{equation*}\]

<p>由n*1的向量矩阵，$R^{4}$
\(y=
\begin{equation*}\begin{bmatrix}
460  \\
232  \\
315  \\
178  
\end{bmatrix}\end{equation*}\)</p>

<p>$y_{1}=460,y_{2}=232$</p>

<p>它是从下标1开始的，计算机中是从0开始的。矩阵通常以大写字母表示的，小写字母表现为标量向量的。</p>

<h3 id="矩阵计算">矩阵计算</h3>

<p>$h_{\theta}(x)=-40+0.25x$</p>

<p>那么矩阵计算过程为
\(\begin{bmatrix}
1&amp;2104  \\
1&amp;1416  \\
1&amp;1534  \\
1&amp;852
\end{bmatrix}
*
\begin{bmatrix}
-40  \\
0.25
\end{bmatrix}
=
\begin{bmatrix}
-40*1+0.25*2104  \\
-40*1+0.25*1416  \\
-40*1+0.25*1534  \\
-40*1+0.25*852
\end{bmatrix}\)</p>

<p>给定3个假定函数</p>
<ol>
  <li>$h_{\theta}(x)=-40+0.25x$</li>
  <li>$h_{\theta}(x)=200+0.1x$</li>
  <li>$h_{\theta}(x)=-150+0.4x$</li>
</ol>

\[\begin{equation*}
\begin{bmatrix}
1&amp;2104  \\
1&amp;1416  \\
1&amp;1534  \\
1&amp;852
\end{bmatrix}
*
\begin{bmatrix}
-40&amp;200&amp;-150  \\
0.25&amp;0.1&amp;0.4
\end{bmatrix}
=
\begin{bmatrix}
486&amp;410&amp;692  \\
314&amp;342&amp;416  \\
344&amp;353&amp;464  \\
173&amp;285&amp;191
\end{bmatrix}
\end{equation*}\]

<h3 id="矩阵特性">矩阵特性</h3>

<p>参考《线性代数》矩阵相关的公式、定义等</p>

<h2 id="多种特征">多种特征</h2>

<p>特征向量，以房价为例</p>

<table>
  <thead>
    <tr>
      <th>面积$m^2$</th>
      <th>卧室数量</th>
      <th>门数量</th>
      <th>房龄</th>
      <th>价格</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>2104</td>
      <td>5</td>
      <td>1</td>
      <td>45</td>
      <td>460</td>
    </tr>
    <tr>
      <td>1416</td>
      <td>3</td>
      <td>2</td>
      <td>40</td>
      <td>232</td>
    </tr>
    <tr>
      <td>1534</td>
      <td>3</td>
      <td>2</td>
      <td>30</td>
      <td>315</td>
    </tr>
    <tr>
      <td>852</td>
      <td>2</td>
      <td>1</td>
      <td>36</td>
      <td>178</td>
    </tr>
    <tr>
      <td>$\ldots$</td>
      <td>$\ldots$</td>
      <td>$\ldots$</td>
      <td>$\ldots$</td>
      <td> </td>
    </tr>
  </tbody>
</table>

<ul>
  <li>n=特征数量</li>
</ul>

\[\begin{equation*}
n=4
\end{equation*}\]

<ul>
  <li>$x^{(i)}$=$i^{th}$训练样本的特征向量</li>
</ul>

\[\begin{equation*}x^{2}=
\begin{bmatrix}
1416  \\
3  \\
2  \\
40
\end{bmatrix}
\end{equation*}
\epsilon R^{4}\]

<ul>
  <li>$x_{j}^{(i)}$=$i^{th}$训练样本的第j个特征量的值</li>
</ul>

\[\begin{equation*}
x_{3}^{(2)}=2
\end{equation*}\]

<p>线性回归的假定函数$h_{\theta}=\theta_{0}+\theta_{1}x$不适用此情况，此时的函数模型应为：</p>

\[\begin{equation*}
h_{\theta}=\theta_{0}+\theta_{1}x_{1}+\theta_{2}x_{2}+\theta_{3}x_{3}-\theta_{4}x_{4}
\end{equation*}\]

<p>意味着后续特征增加时，模型可应为:</p>

\[\begin{equation*}
h_{\theta}=\theta_{0}+\theta_{1}x_{1}+\theta_{1}x_{2}+\ldots+\theta_{n}x_{n}  \\
x=
\begin{bmatrix}
x_{0}  \\
x_{1}  \\
x_{2}  \\
\ldots  \\
x_{n}
\end{bmatrix}\ 
\epsilon\  R^{n+1}
\qquad
\theta=
\begin{bmatrix}
R_{0}  \\
R_{1}  \\
R_{2}  \\
\ldots  \\
R_{n}
\end{bmatrix}
\epsilon\  R^{n+1}  \\
  \begin{split}
    h_{\theta}
    &amp; = \theta_{0}x_{0}+\theta_{1}x_{1}+\theta_{1}x_{2}+\ldots-\theta_{n}x_{n}   \\
	&amp; = \theta_{x}^{T}  \\
  \end{split}  \\
  
\text{其中}  \\

\begin{bmatrix}
\theta_{0}x_{0}&amp;\theta_{1}x_{1}&amp;\ldots&amp;\theta_{n}x_{n}  \\
\end{bmatrix}

\begin{bmatrix}
x_{0}  \\
x_{0}  \\
\ldots  \\
x_{n} 
\end{bmatrix}

\end{equation*}\]

<blockquote>
  <p>为了方便，$\theta_{0}x{0}$的$x{0}=1$,故省去</p>
</blockquote>

<h3 id="多种参数的梯度下降法">多种参数的梯度下降法</h3>

<p>之前最简函数$h_{\theta}=\theta_{0}+\theta_{1}x$的$\theta_{0}$，给出的梯度下降法：</p>

\[\theta_{1}:=\theta_{1}-\vartheta\frac{1}{m}\sum\limits_{i=1}^m (h_{\theta_{(i)}-y^{(i)})}x^{(i)}\]

:ET